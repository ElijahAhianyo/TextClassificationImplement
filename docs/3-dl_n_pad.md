# Dl N Pad

[_Documentation generated by Documatic_](https://www.documatic.com)

<!---Documatic-section-Codebase Structure-start--->
## Codebase Structure

<!---Documatic-block-system_architecture-start--->
```mermaid
None
```
<!---Documatic-block-system_architecture-end--->

# #
<!---Documatic-section-Codebase Structure-end--->

<!---Documatic-section-dl.n_pad.train.eval-start--->
## dl.n_pad.train.eval

<!---Documatic-section-eval-start--->
<!---Documatic-block-dl.n_pad.train.eval-start--->
<details>
	<summary><code>dl.n_pad.train.eval</code> code snippet</summary>

```python
def eval(model, df_vali, gap_size, use_gpu):
    model.eval()
    acc_sum = 0
    ii = 0
    start_vali = 0
    while start_vali + gap_size <= len(df_vali):
        '取一batch数据'
        end_vali = start_vali + gap_size
        df_vali_batch = df_vali.iloc[start_vali:end_vali]
        start_vali = end_vali
        '数据预处理：按句子长度降序排序;pad_sequence'
        df_vali_batch.sort_values(by='length', ascending=False, inplace=True)
        vali_x_batch = list(df_vali_batch.loc[:, 'word_seg'])
        vali_y_batch = list(df_vali_batch.loc[:, 'classify'])
        x_vali_lengths = list(df_vali_batch.loc[:, 'length'])
        vali_x_batch = [torch.Tensor(x_tmp) for x_tmp in vali_x_batch]
        vali_x_batch = rnn.pad_sequence(vali_x_batch, batch_first=True).long()
        x_vali = torch.LongTensor(vali_x_batch)
        y_vali = torch.LongTensor(vali_y_batch)
        if use_gpu:
            x_vali = x_vali.cuda()
            y_vali = y_vali.cuda()
        '前向传播'
        output_vali = model(x_vali, x_vali_lengths)
        acc_batch = torch.mean(torch.eq(torch.max(output_vali, 1)[1], y_vali).float())
        acc_sum += acc_batch
        ii += 1
    acc_mean = acc_sum / (ii + 1)
    model.train()
    return acc_mean
```
</details>
<!---Documatic-block-dl.n_pad.train.eval-end--->
<!---Documatic-section-eval-end--->

# #
<!---Documatic-section-dl.n_pad.train.eval-end--->

<!---Documatic-section-dl.n_pad.data.data_process.word2index-start--->
## dl.n_pad.data.data_process.word2index

<!---Documatic-section-word2index-start--->
<!---Documatic-block-dl.n_pad.data.data_process.word2index-start--->
<details>
	<summary><code>dl.n_pad.data.data_process.word2index</code> code snippet</summary>

```python
def word2index(word):
    if word in word_index_dict:
        return word_index_dict[word]
    else:
        return 0
```
</details>
<!---Documatic-block-dl.n_pad.data.data_process.word2index-end--->
<!---Documatic-section-word2index-end--->

# #
<!---Documatic-section-dl.n_pad.data.data_process.word2index-end--->

<!---Documatic-section-dl.n_pad.data.data_process.sentence2index-start--->
## dl.n_pad.data.data_process.sentence2index

<!---Documatic-section-sentence2index-start--->
<!---Documatic-block-dl.n_pad.data.data_process.sentence2index-start--->
<details>
	<summary><code>dl.n_pad.data.data_process.sentence2index</code> code snippet</summary>

```python
def sentence2index(sentence):
    sentence_list = sentence.strip().split()[:max_length]
    list_index = list(map(word2index, sentence_list))
    return list_index
```
</details>
<!---Documatic-block-dl.n_pad.data.data_process.sentence2index-end--->
<!---Documatic-section-sentence2index-end--->

# #
<!---Documatic-section-dl.n_pad.data.data_process.sentence2index-end--->

<!---Documatic-section-dl.n_pad.word2vec.train_word2vec.sentence2list-start--->
## dl.n_pad.word2vec.train_word2vec.sentence2list

<!---Documatic-section-sentence2list-start--->
<!---Documatic-block-dl.n_pad.word2vec.train_word2vec.sentence2list-start--->
<details>
	<summary><code>dl.n_pad.word2vec.train_word2vec.sentence2list</code> code snippet</summary>

```python
def sentence2list(sentence):
    return sentence.strip().split()
```
</details>
<!---Documatic-block-dl.n_pad.word2vec.train_word2vec.sentence2list-end--->
<!---Documatic-section-sentence2list-end--->

# #
<!---Documatic-section-dl.n_pad.word2vec.train_word2vec.sentence2list-end--->

[_Documentation generated by Documatic_](https://www.documatic.com)